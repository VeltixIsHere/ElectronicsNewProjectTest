# hand_skeleton_gestures.py
# Requires: mediapipe, opencv-python
# Example: py -3.11 -m pip install mediapipe opencv-python
# Run: py -3.11 hand_skeleton_gestures.py

import cv2
import mediapipe as mp
from time import time

mp_drawing = mp.solutions.drawing_utils
mp_hands = mp.solutions.hands

# indices of fingertip and pip (for index/middle/ring/pinky)
FINGER_TIPS = [8, 12, 16, 20]
FINGER_PIPS = [6, 10, 14, 18]

def fingers_up(hand_landmarks):
    """Return list of booleans for index,middle,ring,pinky whether finger is 'up'."""
    # landmarks are normalized (x,y) in [0..1], origin top-left
    ups = []
    for tip_idx, pip_idx in zip(FINGER_TIPS, FINGER_PIPS):
        tip_y = hand_landmarks.landmark[tip_idx].y
        pip_y = hand_landmarks.landmark[pip_idx].y
        # If tip is above pip (smaller y), we consider finger extended
        ups.append(tip_y < pip_y)
    return ups

def detect_gesture(hand_landmarks):
    """Simple heuristic gesture detection using extended fingers (ignores thumb for simplicity)."""
    ups = fingers_up(hand_landmarks)
    count = sum(ups)

    # index and middle extended => peace
    if ups[0] and ups[1] and not ups[2] and not ups[3]:
        return "Peace ‚úåÔ∏è"
    # all four extended -> open hand
    if count == 4:
        return "Open Hand üñêÔ∏è"
    # none extended -> fist
    if count == 0:
        return "Fist ‚úä"
    # only index extended -> pointing
    if ups[0] and not any(ups[1:]):
        return "Pointing ‚òùÔ∏è"
    # fallback - show number of fingers
    return f"{count} fingers"

def draw_label(image, text, xy, bg_color=(0, 0, 0), text_color=(255, 255, 255)):
    """Draw a small label with background at xy (tuple of ints)."""
    x, y = int(xy[0]), int(xy[1])
    font = cv2.FONT_HERSHEY_SIMPLEX
    scale = 0.7
    thickness = 2
    (w, h), _ = cv2.getTextSize(text, font, scale, thickness)
    pad = 6
    cv2.rectangle(image, (x - pad, y - h - pad), (x + w + pad, y + pad//2), bg_color, -1)
    cv2.putText(image, text, (x, y), font, scale, text_color, thickness, cv2.LINE_AA)

def main():
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("Cannot open camera")
        return

    # use default MediaPipe Hands config (tweak as needed)
    with mp_hands.Hands(
        static_image_mode=False,
        max_num_hands=2,
        min_detection_confidence=0.6,
        min_tracking_confidence=0.6
    ) as hands:

        prev_time = time()
        while True:
            ret, frame = cap.read()
            if not ret:
                break

            # Flip for mirror view (optional)
            frame = cv2.flip(frame, 1)
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

            results = hands.process(frame_rgb)

            # Draw landmarks and gestures
            if results.multi_hand_landmarks:
                for i, hand_landmarks in enumerate(results.multi_hand_landmarks):
                    # Draw skeleton
                    mp_drawing.draw_landmarks(
                        frame,
                        hand_landmarks,
                        mp_hands.HAND_CONNECTIONS,
                        mp_drawing.DrawingSpec(color=(0,255,0), thickness=2, circle_radius=3),
                        mp_drawing.DrawingSpec(color=(0,128,255), thickness=2)
                    )

                    # get handedness label (Left / Right)
                    handedness = "Unknown"
                    if results.multi_handedness and i < len(results.multi_handedness):
                        handedness = results.multi_handedness[i].classification[0].label

                    # compute bounding/anchor point: use wrist landmark (0)
                    wrist = hand_landmarks.landmark[0]
                    h, w, _ = frame.shape
                    wrist_px = (int(wrist.x * w), int(wrist.y * h))

                    # detect gesture
                    gesture = detect_gesture(hand_landmarks)

                    # draw labels
                    draw_label(frame, f"{handedness} | {gesture}", (wrist_px[0] - 10, wrist_px[1] - 10),
                               bg_color=(50, 50, 50), text_color=(255,255,255))

            # FPS
            now = time()
            fps = 1.0 / (now - prev_time) if (now - prev_time) > 0 else 0.0
            prev_time = now
            cv2.putText(frame, f"FPS: {int(fps)}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0), 2)

            cv2.imshow("Hand skeleton + gesture", frame)

            # Quit on 'q' or ESC
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q') or key == 27:
                break

    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
